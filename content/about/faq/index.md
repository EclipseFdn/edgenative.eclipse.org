---
title: "Frequently Asked Questions"
date: 2018-04-07T16:09:45-04:00
---

Last Updated: Decemter 5, 2019

<br/>

#### Q: Why is now the right time for the Eclipse Foundation to create an Edge Native Working Group?
A. Edge computing has really started to be acknowledged in the industry as technology that’s independent of IoT and independent of Cloud.

Several IoT projects at the Eclipse Foundation were already starting to consider edge computing, so it was natural to move these projects out from under the IoT umbrella to a new edge native umbrella. By creating a dedicated, standalone Edge Native Working Group, these projects will be able to receive the focused support the market opportunity warrants, both within the field of IoT as well as other domains. 

---

#### Q: What do you mean by “Edge Native”?
A. To understand Edge Native, it is useful to understand what Cloud Native means. “Cloud native” is a modern approach to application building that takes advantage of the cloud computing delivery model. Cloud native applications are architected to run in an elastic and distributed way to optimize for on-demand delivery and global deployment by leveraging agile, scalable deployment units such as containers. In short, cloud native focuses on how applications are created and deployed, not where. Because of the way cloud native applications are architected they can be deployed across technological boundaries. As such, we can take the principles of a cloud native approach into the decentralized, distributed infrastructure known as the Edge. 

However, there are some fundamental differences between the cloud and the edge, specifically the architecture, principles, and primitives. An edge compute platform takes advantage of core edge attributes such as location, network topology and latency, and heterogeneous hardware. Edge native systems are location-aware and incorporate it into their core operations. Moreover, Edge environments expose challenges of connectivity, power management, compute limitations, hardware diversity, and security that are not present in cloud and data center. Although the surface results of an edge computing system may look like the cloud, the underlying functionality must be built for those edge challenges as a matter of first principle in order to be edge native. Because cloud architectures cannot be directly applied to the edge, the desired attributes of the cloud can be made available by edge native systems that abstract away the much greater complexity of edge environments and allow the two worlds to merge seamlessly.

An edge native approach takes into account the primitives and principles of edge computing outlined above and combines it with the modern architectural approach that has come to define cloud native.

It is essential to remember that there is no single “edge”. The edge is anywhere and everywhere outside of traditional IT environments. 

---

#### Q: Why was it important for the Eclipse Foundation to separate the Edge Native Working Group from its open source IoT initiatives?
A. The Eclipse Foundation is doing the same thing for edge computing as it did for IoT. We’re drawing a circle around edge computing to acknowledge that it has a certain set of requirements, challenges, and industry-wide concerns that are different from those found in all other sectors. We’re saying that edge computing is not only on the rise, it’s here to stay. There’s enough going on in the industry that it’s time to address the particular challenges associated with edge computing in a very focused way. 

---

#### Q: Beyond IoT, what are some of the applications for edge computing?
A. Artificial intelligence is a big one. Imagine an AI application that analyzes images from thousands of security cameras installed around an airport. The cost to constantly stream terabytes of data to a cloud datacenter for processing and analysis would blow a monthly data budget in a day. The only solution is to move the AI application — and all of the associated compute capabilities — to the airport so the data only has to flow over the wires and Wi-Fi already installed at the airport to be analyzed.

Autonomous vehicles are another very important application for edge computing. In this case, the latency that occurs when data is sent from the vehicle to the cloud and back again creates huge safety issues. The average latency using the cloud is about 250 milliseconds. But, vehicle safety relies on sub-one-millisecond latency. The only way to respond 250 times faster is to move the compute power and software inside the vehicle.

Finally, industrial automation and robotics are a huge opportunity for Edge Native applications. Moving compute and storage close to machines or even inside robots will make factories more resilient and productive.

---

#### Q: What are some of the key projects the Edge Native Working Group will encompass?
A. The two flagship projects are Eclipse ioFog and Eclipse fog05. These projects were previously growing under Eclipse IoT and there’s already a community around them. So, this is not a working group that’s saying, well, let’s take a look at edge computing and see what we come up with. The Edge Native Working Group is starting with established projects that are already deployed in the field.

This is an extremely important point because the Edge Native Working Group is building on projects with a proven track record in the industry. This is not a theoretical place where people postulate on the future. Rather, it’s the home of production ready code that is forming the foundation for edge computing standards for infrastructure. Plus, the working group will leverage a proven governance model that fosters open innovation at scale.

---

#### Q: What are the overarching goals of the Edge Native Working Group?
A. Our goal is to bring edgeops — devops for the edge — to the world so developers can write software and get it out to the edge so it can run where it needs to, whether that’s on an MRI machine in a hospital, in a vehicle that’s doing some lightweight autonomous driving, or on cameras that are sensing animal movements in an automated agriculture application. We also want to ensure developers can mass-deploy their edge computing technology, for example to an entire fleet of vehicles, once the technology is ready for production.

We’re focused on understanding and resolving the challenges that make the edge so hard and so different from the cloud. What architectures are needed? What should we tackle first? What are some standards and edgeops technologies that developers can use to implement these capabilities in their enterprise systems?

#### Q: What kind of initial interest have seen in joining the Edge Native Working Group?
A. We have seen tremendous interest in this initiative. The Founding members of the working group are ADLINK, Bosch, Edgeworx, Eurotech, Huawei, Intel, Kynetics and Siemens. Some of those names are industry giants; others are medium sized companies and startups. All of them have a strategic interest in edge computing. We are also discussing with many other or

The semiconductor and telecom verticals come to mind as real areas of opportunity where we have seen a lot of interest expressed. 

For chipmakers, the Edge Native Working Group provides access to a developer ecosystem that will expose the powerful capabilities in their AI accelerator silicon products. These days, chips are really only as valuable as the user community that’s developing software for them. Edge computing applications are an ideal way to showcase the speed their products provide for AI and data analytics processing at the edge. 

Telecom vendors’ reasons for joining are also very straightforward. If you have the 5G cell tower of the future and you know your telecom carrier customers are going to be looking for edge computing to enable 5G applications, you want to stay close to where people are building edge computing infrastructure. You can ensure your products align with edge computing standards, and you have an opportunity to help drive those standards.

---

#### Q: What do you say to developers who are intimidated by the idea of developing applications for the edge? 
A. Our goal is to ensure that everything  that grows out of the Eclipse Edge Native Working Group will be focused on developers first. We know developers can’t afford to learn completely new things so our goal is to let people use their existing skills and devops tools, write in their preferred languages, reuse their existing cloud and datacenter applications, and make it all work seamlessly with the edge.

Chances are, if developers have software running in the cloud or in datacenters, they’re already 80 percent of the way there and we can help them push that software out to the edge.

---

#### Q: How can interested developers and organizations get involved?
A. If you want to get in on the ground floor, start by reviewing the charter and the Edge Native Working Group Participation Agreement (WPGA), or email us at membership@eclipse.org. Individually, developers can join the Edge WG mailing list where we’ll be sharing the progress of the working group. Edge is the way of the future, so join us now and take your seat at the table!
